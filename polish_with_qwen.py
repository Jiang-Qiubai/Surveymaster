import os
import re
import json
import argparse
import time
from openai import OpenAI

# ==============================================================================
# âš™ï¸ é…ç½®éƒ¨åˆ†
# ==============================================================================
# é»˜è®¤ API åœ°å€ (æ ¹æ®ä½ çš„ç¯å¢ƒä¿®æ”¹)
DEFAULT_API_BASE = "http://172.17.0.1:8091/v1"
DEFAULT_API_KEY = "EMPTY"
MODEL_NAME = "qwen3-32b" # æˆ–ä½ å®é™…éƒ¨ç½²çš„æ¨¡å‹åç§°

# ==============================================================================
# ğŸ§  å¼•ç”¨è¯­ä¹‰åŒ–ç®¡ç†å™¨ (Semantic Citation Manager)
# ==============================================================================
class CitationManager:
    def __init__(self, bib_path):
        self.bib_path = bib_path
        self.ref_to_semantic = {}   # ref1 -> yang2024code
        self.semantic_to_entry = {} # yang2024code -> @article{...} string
        self._parse_and_build_map()

    def _generate_semantic_key(self, meta):
        """ç”Ÿæˆ authorYearKeyword æ ¼å¼çš„é”®å"""
        # æå–ä½œè€…å§“æ°
        author = "unknown"
        if 'author' in meta:
            first_author = meta['author'].split(' and ')[0] # å–ç¬¬ä¸€ä½œè€…
            # ç§»é™¤ LaTeX è½¬ä¹‰ç¬¦å’Œéå­—æ¯å­—ç¬¦
            author = re.sub(r'[^a-zA-Z]', '', first_author.lower())
        
        year = meta.get('year', 'nd')
        
        # æå–æ ‡é¢˜å…³é”®è¯
        keyword = "ref"
        if 'title' in meta:
            # ç®€å•çš„åœç”¨è¯è¿‡æ»¤
            stopwords = {'the', 'a', 'an', 'on', 'in', 'of', 'for', 'to', 'and', 'with', 'survey', 'review'}
            words = re.findall(r'[a-zA-Z]{3,}', meta['title'].lower())
            for w in words:
                if w not in stopwords:
                    keyword = w
                    break
        
        base_key = f"{author}{year}{keyword}"
        return base_key

    def _parse_and_build_map(self):
        if not os.path.exists(self.bib_path):
            print("âš ï¸ Warning: draft_refs.bib not found.")
            return

        with open(self.bib_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ä½¿ç”¨æ­£åˆ™æå–æ¯ä¸ª bib æ¡ç›®
        # å‡è®¾æ ¼å¼æ ‡å‡†: @type{key, ...}
        entries = re.findall(r'@\w+\{(ref\d+),(.*?)\n\}', content, re.DOTALL)
        
        print(f"ğŸ“– Loaded {len(entries)} citations from draft bib.")

        key_counts = {} # ç”¨äºå¤„ç†é”®åå†²çª

        for ref_id, body in entries:
            # æå–å…ƒæ•°æ®ç”¨äºç”Ÿæˆé”®å
            meta = {}
            for field in ['title', 'author', 'year', 'journal', 'url']:
                match = re.search(f"{field}\s*=\s*[\"{{](.*?)[\"}}]", body, re.IGNORECASE)
                if match: meta[field] = match.group(1)
            
            # ç”Ÿæˆè¯­ä¹‰é”®å
            sem_key = self._generate_semantic_key(meta)
            
            # å†²çªå¤„ç† (zhang2024llm -> zhang2024llm2)
            if sem_key in key_counts:
                key_counts[sem_key] += 1
                sem_key = f"{sem_key}{key_counts[sem_key]}"
            else:
                key_counts[sem_key] = 1

            # å­˜å‚¨æ˜ å°„
            self.ref_to_semantic[ref_id] = sem_key
            
            # é‡å»º Bib æ¡ç›® (æ›¿æ¢åŸæœ¬çš„ refX ä¸º semantic key)
            new_entry = f"@article{{{sem_key},\n{body}\n}}" # ç®€å•é‡å»ºï¼Œä¿ç•™ body
            self.semantic_to_entry[sem_key] = new_entry

    def replace_in_text(self, text):
        """å°† text ä¸­çš„ \cite{ref1} æ›¿æ¢ä¸º \cite{yang2024code}"""
        def replacer(match):
            refs = match.group(1).split(',')
            new_refs = []
            for r in refs:
                r = r.strip()
                if r in self.ref_to_semantic:
                    new_refs.append(self.ref_to_semantic[r])
                else:
                    new_refs.append(r) # æ²¡æ‰¾åˆ°å°±ä¿æŒåŸæ ·
            return f"\\cite{{{','.join(new_refs)}}}"

        return re.sub(r'\\cite\{([^\}]+)\}', replacer, text)

    def generate_final_bib(self, final_text):
        """æ ¹æ®æœ€ç»ˆæ–‡æœ¬ä¸­å®é™…ç”¨åˆ°çš„å¼•ç”¨ï¼Œç”Ÿæˆ clean bib"""
        used_keys = set()
        matches = re.findall(r'\\cite\{([^\}]+)\}', final_text)
        for m in matches:
            for k in m.split(','):
                used_keys.add(k.strip())
        
        final_entries = []
        for k in used_keys:
            if k in self.semantic_to_entry:
                final_entries.append(self.semantic_to_entry[k])
        
        return "\n\n".join(final_entries)

# ==============================================================================
# ğŸ¤– LLM è°ƒç”¨å‡½æ•°
# ==============================================================================
def call_llm(client, prompt, system_prompt="You are a helpful assistant.", max_tokens=4096):
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ LLM Call Failed: {e}")
        return None

# ==============================================================================
# ğŸš€ æ ¸å¿ƒæµç¨‹
# ==============================================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--dir', type=str, required=True, help="Result directory")
    parser.add_argument('--api-base', type=str, default=DEFAULT_API_BASE)
    args = parser.parse_args()

    # åˆå§‹åŒ– OpenAI Client
    client = OpenAI(base_url=args.api_base, api_key=DEFAULT_API_KEY)
    
    # æ–‡ä»¶è·¯å¾„
    draft_tex = os.path.join(args.dir, "draft_paper.tex")
    draft_bib = os.path.join(args.dir, "draft_refs.bib")
    
    if not os.path.exists(draft_tex):
        print("âŒ draft_paper.tex not found. Run storm_to_ieee.py first.")
        return

    # 1. è¯»å– Draft æ­£æ–‡
    # æˆ‘ä»¬éœ€è¦æå– \begin{document} ä¹‹åï¼Œ\bibliographystyle ä¹‹å‰çš„å†…å®¹
    with open(draft_tex, 'r', encoding='utf-8') as f:
        full_latex = f.read()

    # ç®€å•çš„æå– Body é€»è¾‘
    body_match = re.search(r'\\end\{abstract\}(.*?)\\bibliographystyle', full_latex, re.DOTALL)
    if not body_match:
        # å¦‚æœæ²¡æœ‰ abstract å— (draftå¯èƒ½æ²¡æœ‰)ï¼Œå°è¯•ä» maketitle åæå–
        body_match = re.search(r'\\maketitle(.*?)\\bibliographystyle', full_latex, re.DOTALL)
    
    if not body_match:
        print("âŒ Could not extract body from draft_paper.tex")
        return
    
    raw_body = body_match.group(1).strip()

    # 2. è¯­ä¹‰åŒ–å¼•ç”¨ (Pre-processing)
    print("ğŸ”„ [Step 1/4] Semanticizing citations...")
    cit_manager = CitationManager(draft_bib)
    semantic_body = cit_manager.replace_in_text(raw_body)

    # 3. LLM æ¶¦è‰² (Polishing)
    print("âœï¸ [Step 2/4] Polishing body text with Qwen...")
    polish_prompt = f"""
You are an expert academic editor for IEEE Transactions.
Please refine the following LaTeX content.

**Requirements:**
1. Improve the flow, clarity, and academic tone.
2. Connect paragraphs logically.
3. **CRITICAL**: Do NOT remove or modify citation keys (e.g., \\cite{{yang2024code}}). Keep them exactly where they are.
4. **CRITICAL**: Maintain the LaTeX structure (\\section, \\textbf, etc.).
5. Output ONLY the refined LaTeX body code. No markdown code blocks, no intro text.

**Content to Polish:**
{semantic_body[:25000]} 
""" # æˆªæ–­ä»¥é˜²è¶…é•¿
    
    polished_body = call_llm(client, polish_prompt, system_prompt="You are a strict LaTeX editor.")
    if not polished_body:
        print("âš ï¸ Polishing failed, using semantic draft.")
        polished_body = semantic_body
    
    # æ¸…ç†ä¸€ä¸‹ LLM å¯èƒ½è¾“å‡ºçš„ ```latex ... ```
    polished_body = re.sub(r'^```latex', '', polished_body).replace('```', '').strip()

    # 4. LLM ç”Ÿæˆæ ‡é¢˜å’Œæ‘˜è¦ (Metadata Gen)
    print("ğŸ§  [Step 3/4] Generating Title & Abstract from polished text...")
    meta_prompt = f"""
Based on the following academic paper content, generate a high-quality Title and Abstract.

**Content:**
{polished_body[:10000]}... (truncated)

**Output Format:**
Return a JSON object strictly:
{{
  "title": "Your Generated Title Here",
  "abstract": "Your generated abstract here (approx 150-250 words)."
}}
"""
    meta_response = call_llm(client, meta_prompt, system_prompt="You are a JSON generator.")
    
    try:
        # å°è¯•æå– JSON
        json_match = re.search(r'\{.*\}', meta_response, re.DOTALL)
        if json_match:
            meta_data = json.loads(json_match.group(0))
        else:
            raise ValueError("No JSON found")
            
        title = meta_data.get('title', 'AI Generated Survey')
        abstract = meta_data.get('abstract', 'Summary generation failed.')
    except Exception as e:
        print(f"âš ï¸ Metadata generation failed: {e}. Using placeholders.")
        title = "AI Generated Survey (Polished)"
        abstract = "Abstract generation failed. Please review the body text."

    # 5. ç»„è£…æœ€ç»ˆ LaTeX (Assembly)
    print("ğŸ“ [Step 4/4] Assembling final_paper.tex...")
    
    final_latex = f"""\\documentclass[conference]{{IEEEtran}}
\\usepackage{{cite}}
\\usepackage{{amsmath,amssymb,amsfonts}}
\\usepackage{{algorithmic}}
\\usepackage{{graphicx}}
\\usepackage{{textcomp}}
\\usepackage{{xcolor}}
\\usepackage{{url}}
\\def\\BibTeX{{{{\\rm B\\kern-.05em{{\\sc i\\kern-.025em b}}\\kern-.08em
    T\\kern-.1667em\\lower.7ex\\hbox{{E}}\\kern-.125emX}}}}

\\begin{{document}}

\\title{{{title}}}
\\author{{\\IEEEauthorblockN{{Generated by STORM & Qwen}}}}

\\maketitle

\\begin{{abstract}}
{abstract}
\\end{{abstract}}

\\begin{{IEEEkeywords}}
Large Language Models, Code Intelligence, Survey, Artificial Intelligence
\\end{{IEEEkeywords}}

{polished_body}

\\bibliographystyle{{IEEEtran}}
\\bibliography{{final_refs}}

\\end{{document}}
"""

    # ç”Ÿæˆ Clean Bib
    final_bib_content = cit_manager.generate_final_bib(polished_body)

    # å†™å…¥æ–‡ä»¶
    out_tex = os.path.join(args.dir, "final_paper.tex")
    out_bib = os.path.join(args.dir, "final_refs.bib")
    
    with open(out_tex, 'w', encoding='utf-8') as f: f.write(final_latex)
    with open(out_bib, 'w', encoding='utf-8') as f: f.write(final_bib_content)

    print("-" * 40)
    print("ğŸ‰ Polishing Complete!")
    print(f"   Final TeX: {out_tex}")
    print(f"   Final Bib: {out_bib}")

if __name__ == "__main__":
    main()