import os
import re
import argparse
import logging
import arxiv
import dspy
import sys
from sentence_transformers import SentenceTransformer

# --- 1. LiteLLM é™éŸ³é…ç½® ---
os.environ["LITELLM_LOG"] = "ERROR" 
import litellm
litellm.suppress_debug_info = True
litellm.set_verbose = False
litellm.drop_params = True

from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs
from knowledge_storm.lm import LitellmModel
from knowledge_storm.utils import load_api_key

# å¼•å…¥éœ€è¦ Monkey Patch çš„æ¨¡å—
import knowledge_storm.storm_wiki.modules.persona_generator as pg_module
import knowledge_storm.storm_wiki.modules.storm_dataclass as storm_dataclass
# å¼•å…¥éœ€è¦ä¿®æ”¹ Prompt çš„æ¨¡å— (è¿™æ˜¯å…³é”®)
import knowledge_storm.storm_wiki.modules.outline_generation as outline_gen_module
import knowledge_storm.storm_wiki.modules.article_generation as article_gen_module

# ==============================================================================
# 0. ç¡¬ç¼–ç é…ç½®åŒºåŸŸ
# ==============================================================================
LLM_API_URL = "http://172.17.0.1:8091/v1"
LLM_MODEL_NAME = "openai/qwen3-32b"
# ä¸ºäº†æ”¯æŒé•¿æ–‡ï¼Œæ£€ç´¢æ·±åº¦å¿…é¡»å¢åŠ 
SEARCH_TOP_K = 10      # æ¯ä¸€è½®æœç´¢æ›´å¤šçš„è®ºæ–‡ (åŸ5)
RETRIEVE_TOP_K = 10    # æ¯ä¸€æ®µå†™ä½œå‚è€ƒæ›´å¤šçš„ç‰‡æ®µ (åŸ5)
MAX_CONV_TURNS = 5     # å¢åŠ å¯¹è¯è½®æ•°ä»¥è¦†ç›–æ›´å¤šå­è¯é¢˜ (åŸ3)
MAX_TOKENS_WRITE = 16384 # å†™ä½œæ—¶å…è®¸çš„æœ€å¤§è¾“å‡ºé•¿åº¦

# æœ¬åœ° Embedding æ¨¡å‹è·¯å¾„
LOCAL_EMBEDDING_PATH = "~/models/paraphrase-MiniLM-L6-v2"

# ==============================================================================
# 2. Monkey Patch åŒºåŸŸ (ä¿æŒä¸å˜ï¼Œç¡®ä¿ç½‘ç»œå’ŒEmbeddingæ­£å¸¸)
# ==============================================================================
def bypass_wiki_access(url):
    return "Academic Topic Placeholder", "Content skipped: Local Academic Mode."

pg_module.get_wiki_page_title_and_toc = bypass_wiki_access

def local_prepare_table_for_retrieval(self):
    model_path = os.path.expanduser(LOCAL_EMBEDDING_PATH)
    print(f"ğŸ§  [Embedding] Loading local model from: {model_path}")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Local embedding model not found at {model_path}")
    self.encoder = SentenceTransformer(model_path, device="cpu", local_files_only=True)
    self.collected_urls = []
    self.collected_snippets = []
    for url, information in self.url_to_info.items():
        for snippet in information.snippets:
            self.collected_urls.append(url)
            self.collected_snippets.append(snippet)
    self.encoded_snippets = self.encoder.encode(self.collected_snippets, show_progress_bar=False)

storm_dataclass.StormInformationTable.prepare_table_for_retrieval = local_prepare_table_for_retrieval

# ==============================================================================
# 1. è‡ªå®šä¹‰ LLM ç±» (ä¿æŒæ¸…æ´—é€»è¾‘)
# ==============================================================================
class CleanLitellmModel(LitellmModel):
    def __call__(self, prompt, **kwargs):
        kwargs['logger_fn'] = None 
        kwargs['verbose'] = False
        outputs = super().__call__(prompt, **kwargs)
        cleaned_outputs = []
        for out in outputs:
            if not isinstance(out, str):
                cleaned_outputs.append(out)
                continue
            cleaned = re.sub(r"<think>.*?</think>", "", out, flags=re.DOTALL).strip()
            cleaned = re.sub(r"^<think>.*", "", cleaned, flags=re.DOTALL).strip()
            cleaned = re.sub(
                r"^(Okay|Sure|Here is|Certainly|Let's|To answer|Great|I can help|Based on).*?[:\n]", 
                "", cleaned, flags=re.IGNORECASE | re.MULTILINE
            ).strip()
            json_match = re.search(r"```json(.*?)```", cleaned, re.DOTALL)
            if json_match:
                cleaned = json_match.group(1).strip()
            elif "```" in cleaned:
                code_match = re.search(r"```(.*?)```", cleaned, re.DOTALL)
                if code_match:
                    cleaned = code_match.group(1).strip()
            cleaned_outputs.append(cleaned)
        return cleaned_outputs

# ==============================================================================
# 3. ArXiv æ£€ç´¢æ¨¡å— (ä¿æŒé˜²å´©æºƒ)
# ==============================================================================
class ArXivSearch(dspy.Retrieve):
    def __init__(self, k=5, category="cs.SE"):
        super().__init__(k=k)
        self.k = k
        self.category = category
        self.client = arxiv.Client()

    def forward(self, query_or_queries, exclude_urls=[]):
        queries = [query_or_queries] if isinstance(query_or_queries, str) else query_or_queries
        collected_results = []
        for query in queries:
            safe_query = query.replace(':', ' ').replace('-', ' ').replace('"', '').strip()
            safe_query = re.sub(r'\b(query|queries)\b', '', safe_query, flags=re.IGNORECASE).strip()
            if not safe_query or '<' in safe_query: continue
            search_query = f'{safe_query}'
            if self.category:
                search_query += f' AND cat:{self.category}'
            
            print(f"ğŸ” [ArXiv] Searching: {search_query}")
            try:
                search = arxiv.Search(query=search_query, max_results=self.k, sort_by=arxiv.SortCriterion.Relevance)
                results = list(self.client.results(search))
                for r in results:
                    collected_results.append({
                        'url': r.entry_id,
                        'title': r.title.replace('\n', ' '),
                        'description': r.summary.replace('\n', ' '),
                        'snippets': [r.summary.replace('\n', ' ')] 
                    })
            except Exception as e:
                print(f"âš ï¸ ArXiv Search Error: {e}")
        
        if not collected_results:
            print("âš ï¸ [Warning] No results found. Returning placeholder.")
            collected_results.append({
                'url': 'http://placeholder/no-results',
                'title': 'No Academic Papers Found',
                'description': 'Search returned no results.',
                'snippets': ['No relevant information found in ArXiv.']
            })
        return collected_results

# ==============================================================================
# 4. ä¸»ç¨‹åº (æ³¨å…¥æ ¸å¿ƒé€»è¾‘)
# ==============================================================================
def main():
    parser = argparse.ArgumentParser(description="STORM ArXiv Deep Review (Long Version)")
    parser.add_argument('--topic', type=str, required=True, help="è®ºæ–‡ç»¼è¿°ä¸»é¢˜")
    parser.add_argument('--output-dir', type=str, default="./results/arxiv_review_long", help="è¾“å‡ºç›®å½•")
    parser.add_argument('--arxiv-category', type=str, default="cs.AI", help="ArXivåˆ†ç±»")
    
    args = parser.parse_args()

    # 1. é¢˜ç›®å¢å¼ºï¼šå¼ºåˆ¶åŠ ä¸Š "Comprehensive Survey" ç­‰è¯ï¼Œå¼•å¯¼æ¨¡å‹å¾€å¤§äº†å†™
    survey_topic = f"A Comprehensive and Deep Academic Survey on {args.topic}: Theories, Methodologies, and Future Directions"
    print(f"ğŸš€ å¯åŠ¨æ·±åº¦ç»¼è¿°ä»»åŠ¡: {survey_topic}")
    print(f"ğŸ¤– è¿æ¥ LLM: {LLM_MODEL_NAME}")

    # 2. åˆå§‹åŒ–æ¨¡å‹ (å¢åŠ  max_tokens ä»¥æ”¯æŒé•¿æ–‡ç”Ÿæˆ)
    conv_lm = CleanLitellmModel(
        model=LLM_MODEL_NAME, api_key='EMPTY', api_base=LLM_API_URL, model_type='chat',  
        max_tokens=2048, temperature=0.8, top_p=0.9
    )
    article_lm = CleanLitellmModel(
        model=LLM_MODEL_NAME, api_key='EMPTY', api_base=LLM_API_URL, model_type='chat', 
        max_tokens=MAX_TOKENS_WRITE, # å…è®¸ç”Ÿæˆæ›´é•¿çš„æ®µè½
        temperature=0.7, # ç¨å¾®æé«˜æ¸©åº¦ï¼Œå¢åŠ åˆ†æçš„å¤šæ ·æ€§
        top_p=0.9
    )

    lm_config = STORMWikiLMConfigs()
    lm_config.set_conv_simulator_lm(conv_lm)
    lm_config.set_question_asker_lm(conv_lm)
    lm_config.set_outline_gen_lm(article_lm)
    lm_config.set_article_gen_lm(article_lm)
    lm_config.set_article_polish_lm(article_lm)

    rm = ArXivSearch(k=SEARCH_TOP_K, category=args.arxiv_category)

    runner_args = STORMWikiRunnerArguments(
        output_dir=args.output_dir,
        max_conv_turn=MAX_CONV_TURNS, # å¢åŠ è½®æ•°ï¼Œæœé›†æ›´å¤šä¿¡æ¯
        max_search_queries_per_turn=3,
        retrieve_top_k=RETRIEVE_TOP_K, # å¢åŠ é˜…è¯»é‡ï¼Œä¸ºé•¿æ–‡æä¾›ç´ æ
        max_thread_num=4, 
        search_top_k=SEARCH_TOP_K
    )

    runner = STORMWikiRunner(runner_args, lm_config, rm)

    # ==============================================================================
    # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ³¨å…¥æ·±åº¦ Prompt (åŸºäºä½ çš„å»ºè®®)
    # ==============================================================================
    print("ğŸ¨ æ³¨å…¥æ·±åº¦å­¦æœ¯åˆ†æ Prompt...")
    
    # 1. å¤§çº²ç”Ÿæˆ Promptï¼šå¼ºåˆ¶è¦æ±‚åŒ…å«å†å²ã€æ–¹æ³•è®ºå¯¹æ¯”ã€ç†è®ºæ¡†æ¶ç­‰ç« èŠ‚
    outline_gen_module.WritePageOutline.__doc__ = """
    Write a highly detailed, comprehensive academic literature review outline for the given topic.
    
    REQUIRED STRUCTURE (Must include these perspectives):
    1. **Historical Context**: Evolution of the field, key milestones.
    2. **Theoretical Foundations**: Core definitions, conflicting theories, theoretical evolution.
    3. **Methodological Analysis**: 
       - Compare different approaches (e.g., Qualitative vs Quantitative, Deep Learning vs Traditional).
       - Discuss advantages and limitations of each method.
    4. **Empirical Evidence**: Categorize studies by design, sample, or setting. Explain contradictory results.
    5. **Critical Gaps & Future Directions**: Unsolved problems, emerging trends.
    
    FORMATTING:
    - Use "#" for main sections and "##", "###" for subsections.
    - Ensure the outline is deep and granular (aim for at least 8-10 main sections).
    - Do not include the topic name itself as a section header.
    """

    # 2. ç« èŠ‚å†™ä½œ Promptï¼šå¼ºåˆ¶è¦æ±‚â€œåˆ†ææ€§å†™ä½œâ€è€Œéâ€œæè¿°æ€§å†™ä½œâ€
    # å°†ä½ æä¾›çš„â€œæ®µè½çº§æ‰©å†™æŠ€å·§â€å†™å…¥ Prompt
    article_gen_module.WriteSection.__doc__ = """
    Write an extensive, analytical, and critical academic review section based on the collected information.
    
    CRITICAL WRITING GUIDELINES (Follow strictly):
    1. **Shift from Description to Analysis**:
       - BAD: "Study A found X. Study B found Y."
       - GOOD: "Study A found X, whereas Study B proposed Y. This discrepancy may stem from methodological differences..."
    2. **Paragraph Structure**:
       - Start with a **Core Argument**.
       - Provide **Supporting Evidence** from multiple sources.
       - Introduce **Contrasting Views** or turning points.
       - Analyze the **Methodological Reasons** for differences.
       - Conclude with **Implications** or Gaps.
    3. **Depth**:
       - Each subsection must be substantive (aim for 500-800 words per section if info permits).
       - Compare and contrast theories/methods explicitly.
    4. **Citations**:
       - Use [1], [2] format inline.
       - Do not create a separate Reference list.
    """

    # ==============================================================================
    # 7. å¼€å§‹è¿è¡Œ
    # ==============================================================================
    print("ğŸ å¼€å§‹æ‰§è¡Œæ·±åº¦ STORM æµç¨‹ (é¢„è®¡è€—æ—¶è¾ƒé•¿)...")
    
    try:
        runner.run(
            topic=survey_topic,
            do_research=True,
            do_generate_outline=True,
            do_generate_article=True,
            do_polish_article=True
        )
        runner.post_run()
        runner.summary()
        print(f"âœ… ç»¼è¿°å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {os.path.join(args.output_dir, runner.article_dir_name)}")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    logging.getLogger("LiteLLM").setLevel(logging.WARNING) 
    logging.getLogger("litellm").setLevel(logging.WARNING) 
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("arxiv").setLevel(logging.WARNING)
    logging.getLogger("dspy").setLevel(logging.WARNING)
    logging.getLogger("sentence_transformers").setLevel(logging.WARNING)

    main()